自然语言处理-文本分类-文本表示 向量空间模型[可参考https://blog.csdn.net/panjiao119/article/details/78265857]

1.向量空间模型（vector space model）：
把对文本内容的处理简化为向量空间中的向量运算，并且它以空间上的相似度表达语义的相似度，直观易懂。当文档被表示为文档空间的向量，就可以通过计算向量之间的相似性来度量文档间的相似性。文本处理中最常用的相似性度量方式是余弦距离。
2.VSM基本概念：
1）文档（Document）：泛指一般的文本或者文本中的片断(段落[段是从文章结构的角度讲的，它是组成文章的一部分。]、句群[句群是语法概念，指共同表示一个中心语义的一组句子。]或句子)，一般指一篇文章。
2）项（Item）：文本的内容特征常常用它所含有的基本语言单位(字、词、词组或短语等)来表示。这些基本的语言单位被统称为文本的项，即文本可以用项集(Term List)表示为D(T1,T2,...,Tk,...,Tn)，1≤k≤n。
3）项的权重（Term Weight）：对于含有n个项的文本，项常常被赋予一定的权重表示他们在文本D中的重要程度。
4）向量空间模型（VSM）：给定一文本D=D(,...,），由于项在文本中既可以重复出现又应该有先后次序的关系，分析起来有一定困难。为了简化分析，暂时不考虑的顺序，并要求互异，这时可以把文本D看作是一个n维的坐标，项就是n维坐标所对应的值，所以文档D()就可以被看作一个n维的向量了。
5）相似度（Similarity）：两个文本D和DZ之间的(内容)相关程度(Degree of Relevance)常常用他们之间的相似度Sim(,)来度量。当文本被表示为向量空间模型时，我们可以借助向量之间的某种距离来表示文本间的相似度。常用向量之间的内积或者用夹角的余弦值表示进行计算。
3.VSM比较关键的部分
1）特征项选择：在构成文本内容的单元中选择用来表示特征项的单元。
①．用来表示文档内容的项可以是各种类别。对汉语来说，有字、词、短语，甚至是句子或句群等更高层的单位，也可以是相同词或短语的语义概念类。
②．项的选择必须由处理速度、精度、存储空间等方面的具体要求来决定。
③．特征项选择原则：应当选取包含语义信息较多，对文本的表示能力较强的语言单位作为特征项；文本在这些特征项上应当有较为明显的统计规律性（这样适用于信息检索、文档分类等应用系统）；特征选取过程应该容易实现，其时间和空间复杂度都不太大。
④．实际应用中，常常采用字、词或短语作为特征项。
⑤．由于词汇是文本的最基本表示项，在文本中的出现频度较高，呈现一定的统计规律。因此，在考虑到处理大规模真实文本所面临的困难，一般选择词汇或短语作为特征项，但是，直接选用文本中的词或词组作为文本特征项会存在问题：Ⅰ.文本中存在一些没有实在意义但使用频率很高的虚词[从、和、的、吧、啊等。]，常常把一些真正有分类作用的实词淹没掉了。
解决方案：
创建一个禁用词表：词表的选择很关键，很难覆盖全部的禁用词；并且语言是不断发展的，词表也是随着训练文本集合的不同而发生变化（对于同一个词在D1文本中是禁用词，但在D2文本中不是禁用词）。另一方面，最能代表一篇文章实际意义的词，往往是实词（形容词、动词 、名词等），但当一个词处于不同的词性时，可能分别属于或者不属于禁用词（“它快速地在地上移动着。”第一个“地”是副词，应该被禁用；第二个“地”是实词，不应该被禁用）。针对这个现象，提出了只提取形容词、动词、名词作为特征项的方法来尝试取代禁用词表。
进行权值计算时，把它们的权值设置为很低的数值，通过取阈值将它们丢弃。
Ⅱ.采用词语作为特征项时还会出现所谓的同义现象。同义现象是指：对于同一个事物，不同人基于不同需要、不同环境、不同知识水平、不同语言习惯等有着不同的表达方法（“电脑”和“计算机”是同一个概念，应该属于同一个特征项），目前最常用的解决方案是采用概念词典来解决这个问题。
2）分词[可参考https://blog.csdn.net/chengzheng_hit/article/details/54753361]：把文本分割成特征项的表示。
①.词是最小的能够独立活动的有意义的语言成分，但在汉语中以字为基本的书写单位。文本中词与词之间没有明确的分割标记，而是连续的汉字串。因此，自动识别词边界，将汉字串分为正确的词串的汉语分词问题是实现中文信息处理各项任务的基础和关键。
②.中文词语分析一般包括三个过程：预处理过程的词语粗切分、切分排歧与未登录词识别[不在词典中的词。]、词性标注。
③.目前中文词语分析采取的主要步骤是：先采取最大匹配、最短路径、概率统计、全切分等方法，得到一个相对较好的粗分结果；然后进行排歧、未登录词识别；最后标注词性。在实际系统中，这三个过程可能相互交叉、反复融合，也可能不存在明显的先后顺序。
④.可以将现在的分词算法分为3大类：基于字符串匹配的分词方法、基于理解的分词方法、基于统计的分词方法。
Ⅰ.基于字符串匹配的分词方法/机械分词法
它按照一定的策略将待分析的汉字串与机器字典中的词条进行匹配，若在字典中可以找到某个字符串，则匹配成功（即识别一个词）。
按照扫描方向的不同可以分为正向匹配和逆向匹配；
按照不同长度优先匹配的情况，又可以分为最大（最长）匹配和最小（最短）匹配；
按照是否与词性标注过程相结合，又可以分为单纯分词法和分词与标注结合的一体化方法。
由于汉语很少单字成词的特点，正向最小匹配和逆向最小匹配一般很少使用。
A.最大匹配法（maximum matching method，MM）
在计算机中存放一个已知的词表（底表），从被切分的语料[语料，即语言材料。语料是构成语料库的基本单元。一个文本集合是一个语料库；当有几个这样的文本集合的时候，我们称之为语料库集合。]中，按给定的顺序截取一个定长的字符串（通常为6-8个汉字），这个字符串的长度叫做最大词长[底表里最长的词长。]。把这个具有最大词长的字符串与底表中的词相匹配，若匹配成功，则可以确定这个字符串为词，然后指针向给定的方向移动与已经识别出的词长相应个数的汉字，继续进行匹配。否则，把该字符串逐次减一，再与底表中的词长进行匹配，知道成功为止。MM原理简单，易于在计算机上实现，实现复杂度较低；但最大词长难以确定，如果定的过长，则算法复杂度显著提高，如果定的过短，则不能切分大于它的词，导致切分正确率降低。
B.逆向最大匹配法（reverse maximum matching method， RMM）
这种方法的原理与MM相同，不同的是切词的扫描方向，如果MM的方向是从左到右取字符串进行匹配，则RMM的切词方向就是从右到左取字符串进行匹配。由于汉语中偏正结构（中心语靠后）较多，若从后向前匹配，可以适当提高精确度。试验证明RMM的切词正确率较MM更高一些[单纯使用正向最大匹配的错误率为 1/16 9,单纯使用逆向最大匹配的错误率为 1/245。
举例：
待分词的字符串序列为“永和服装有限公司”：
正向最大匹配算法的结果为:永,和服,装,有限公司；
逆向最大匹配算法执行结果为:永,和,服装,有限公司。
由此可知,RMM比MM在处理歧义等语言方面更有优势,出错率更低，但仍会出错。
举例：
待分词的字符串序列为“他明白天为什么下雨”：
正向最大匹配算法的结果为:他,明白,天,为什么，下雨；
逆向最大匹配算法执行结果为:他,明,白天,为什么，下雨。]。但是，RMM要求配置逆序的切词字典，这种词典与人们的语言习惯不同。
在实际处理时，先将文档进行倒排处理，生成逆序文档。然后，根据逆序词典，对逆序文档用正向最大匹配法处理即可。
C.逐词遍历匹配法[具体的实现流程]
这种方法把词典中的词按由长到短的顺序，逐个与待切词的语料进行匹配，直到把语料中所有的词都切分出来为止。由于这种方法要把词典中的每个词都匹配一遍，需要花费很多时间，算法的时间复杂度相应增加，效率不高。
D.双向扫描法
这种方法是分别用MM和RMM进行正向和逆向扫描完成初步的切分，并将用MM初步切分的结果与用RMM初步切分结果进行比较，如果两种结果一致，则判定正确；否则定为疑点，此时可以结合上下文信息，或进行人工干预，选取一种切分为正确结果。由于要进行双向扫描，时间复杂度增加，而且为了使切分词典能同时支持正向与逆向两种顺序的匹配和搜索，词典的结构比一般的切词词典复杂。
E.最佳匹配法（optimum matching method，OM）
这是在切词词典中按照词出现频率的大小排列词条，高频词在前，低频词在后，从而缩短了查询切词词典的时间，加快切词的速度，使切词达到最佳的效率。这种切词方法只是改变了词典的排列顺序，只降低了分词的时间复杂度，并没有提高分词的正确性。
F.设立切分标记法
在书面语中，存在的切分标记有两种：一种是自然的切分标志，如标点符号，词不能跨越标点符号而存在，标点符号则是词的边界所在；另一种是非自然的切分标志，如只能在词首出现的词首字，只能在词尾出现的词尾字，没有构词能力的单音节单纯词[由一个语素构成的词语叫做单纯词。单音节的如天、江、水、田等，双音节的如淑典、穹根、弘开等，都是单纯词。]、多音节单纯词、拟声词等，词显然也不能跨越这些词而存在，它们也必然是词的边界。如果收集了大量的这种切分标志，分词时先找到切分标志，就可以把句子切分成一些较短的字段，然后再用MM或RMM进行进一步分析。使用这种方法，需要额外的时间来扫描切分标志同时还需要额外的空间来存储非自然切分标志，使分词的复杂度都大大增加，但换来的正确率提高很有限。
G.有穷多级列举法
这种方法把现代汉语中的全部词分为两部分：一类是开放词（名词、动词、形容词等，它们的成员几乎是无穷的）；一类是闭锁词（连词、助词、叹词等，他们的成员是可以一一枚举的）。分词时，先切出词的特殊标志的字符串（阿拉伯数字、拉丁字母等），再切出可枚举的闭锁词，最后再逐级切出开放词。这是完全立足于语言学的切词方法，在计算机上实现还是具有难度的。

由于分词是一个智能决策过程，机械分词方法无法解决分词阶段的两大基本问题:歧义切分问题和未登陆词识别问题。实际使用的分词系统，都是把机械分词作为一种切分手段，还需通过利用各种其他的语言信息来进一步提高切分的正确率。
对于机械分词方法，可以建立一个通用模型，形式化地表示为ASM(d,a,m)，即“Automatic Segmentation Model”其中：
d：匹配方向，+1表示正向，-1表示逆向；
a：每次匹配失败后增加/减少字符串长度（字符数），+1为增字，-1为减字；
m：最大/最小匹配标志，+1为最大匹配，-1为最小匹配。
例如：ASM(+,-,+)就是正向减字最大匹配法（即MM）；ASM(-,-,
+)就是逆向减字最大匹配法（即RMM）等等。对于现代汉语来说，只有m=+1是实用的方法。
Ⅱ.基于理解的分词方法[深入理解]
A.通常的分词系统，都力图在分词阶段消除所有歧义切分现象；有些系统则在后续过程中来处理歧义切分问题，其分词过程只是整个语言理解过程的一个小部分。
B.在分词阶段尽力消除歧义切分的分词系统，其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。
C.通常包括3个部分：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。由于汉语语言知识的笼统、复杂性，难以将各种语言信息组织成机器可直接读取的形式。因此，目前基于理解的分词系统还处于试验阶段，联想回溯法就是其中的一种。
D.联想-回溯法(association-backtracking method，AB)：要求建立知识库-特征词词库、实词词库和规则库。首先将待切分的汉字字符串序列分割为若干子串，子串可以是词，也可以是由几个词组合成的词群；然后就利用实词词库和规则库将词群细分为词。
E.切词时，要利用一定的语法知识，建立联想机制和回溯机制。
F.联想机制由联想网络和联想推理构成。联想网络描述每个虚词的构词能力，联想推理利用相应的联想网络来判定所描述的虚词究竟是单独的词还是作为其他词中的构成成分。回溯机制主要用于处理歧义句子的切分。联想回溯算法虽然增加了算法的时间复杂度和空间复杂度，但是这种方法的切词正确率得到了有效地提高。
Ⅲ.基于统计的分词方法

3）特征值抽取：在分词产生的词条中选择能够凸显文本特点的词条作为特征值。
一篇文章在经过了分词处理之后，会产生很多词条。如果一个文档所有词条都被作为其特征，将会使特征项异常庞大，而且这样的特征项会使得每个特征项所含信息非常平滑，有用信息反而不会突出。
因此我们需要进行特征项选取，把词条中最能代表某类文本信息的词条挑选出来，作为文本的特征项。试验结果表明简化特征项不但不会使分类结果准确率降低,而且还会使结果更加准确。
特征项选择一般使用统计方法。利用各种计算公式，计算词代表的信息含量，确定一个阀值，将低于阀值的词语过滤掉；或者确定一个特征项数目n，保留处于信息含量在前n位的词条。
特征抽取算法是文本自动分类中的一项关键技术和瓶颈技术，如何从原始文本特征集合中选择最能表示文本主题内容的特征子集，是文本特征抽取算法的研究目标。目前，有多种特征抽取算法被用于文本自动分类的研究中，但这些算法都有其优点和缺点，没有公认的最优方法，需要针对具体系统进行对比来确定最优方法。
特征选择可以从两个方面提高系统性能，一是分类速度，通过特征选择可以大大减少特征集合中的特征数，降低文本向量的维数，简化计算，防止过度拟合，提高系统运行速度。二是准确率，通过适当的特征选择，不但不会降低系统准确性，反而会使系统精度提高。
在文本处理中，一些常用特征提取评估函数有文档频数（document frequency）、信息增益（information gain）、期望交叉熵（expected cross entropy）、互信息（mutual information）、统计（CHI）、文本证据权（the weight of evidence for text）等。
Ⅰ.文档频数DF
这是最简单的评估函数，使用的值为训练集合中该单词发生的文本数。DF评估函数的理论假设稀有单词可能不包含有用信息，也可能太少而不足以对分类产生影响，也可能是噪音，因此可以删去。显然它在计算量上比其他评估函数小很多，但是实践运用中它的效果却很好。DF的缺点是稀有单词可能在某一类文本中并不稀有，也可能包含着重要的判断信息，错误的舍弃，可能影响分类器的精度。因此在实际运用中一般并不直接使用DF。
Ⅱ.信息增益[可参考进行理解https://blog.csdn.net/guo1988kui/article/details/78427409]
信息增益表示文档中包含某一特征值时文档类的平均信息量。它定义为某一特征在文档中出现前后的信息熵之差。
4）特征值赋权

5）TF-IDF权重
特征项的权重计算是文本相似度计算中的一个非常重要的环节。一篇文本中的特征项数目众多，要想得到比较准确的对文本内容的数学化表示，我们需要对能显著体现文本内容特征的特征项赋予高权重，而对不能可以体现文本内容特征的特征项赋予低权重。从效率方面来说，特征项权重的计算是文本相似度计算中的主要工作，它的效率也直接影响文本相似度计算的整体效率。
TF权值反映了特征项在给定的文本中的概念重要程度（freq importance），体现了信息论中频度的思想。某特征项在文本中的出现次数越多，表示它对于该文本的重要程度越高。IDF权值则反映了特征项的信息度（informativeness），用于体现一个特征项的“文义甄别能力”。如果一个特征项只出现在一个或少数文本中，那么它很可能是能体现文本内容特征的语义中心词，会被赋予大的 IDF 值以提高权重。而如果一个特征项在很多的文本中出现过，表示它代表文本的“个性特征”的能力很低，IDF 值也就相应地小。
TF-IDF 权重综合考虑了不同的词在文本中的出现频率(TF 值)和这个词对不同文本的分辨能力(IDF 值)。在所有文本中出现次数很少的特征项被赋予高权重，因为它们被认为是文本内容特征的辨别器。例如，在汉语中“是”的出现频率非常高，但由于它在很多文本中都出现，会被赋予一个很低的 IDF 值，以此体现它对于我们分辨文本的特征并没有太大的帮助。而像“偏微分”这种专业词汇由于只会在相关专业文本中才会出现，会被赋予高 IDF 值以体现它的文本特征鉴别能力。
TF-IDF 是基于统计的权重计算方式，在全局文本集包含的语料特征足够的情况下，这种基于统计学的方法经过实践检验是一种有效的特征项权重衡量方法。其局限性在于它的准确度受全局文本集的影响较大：全局文本集越大，语料越完备，所得的权重也就越准确，但相应地计算效率也会随着全局文本集的增大而降低。
[以下资料参考https://blog.csdn.net/quicmous/article/details/71263844
http://www.ruanyifeng.com/blog/2013/03/tf-idf.html
http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html]
I.词频（TF）
一个词在一个句子中出现的次数越多，那么这个词在描述这个句子的含义方面贡献度越大。
Ⅱ.文档频率（DF）
Ⅲ.逆文档频率（IDF）
Ⅳ.TF/IDF
在这个平均编码长度中，每个关键词都做出了不同的贡献。我们将关键词在文档中的重要性量化为对平均编码长度的贡献上。不难得出如下结论：越是出现次数多（词频高）且罕见的词汇（文档频率低）的关键词对平均编码长度大小的贡献越大。
这里把文档看作信息源，需要通过信道传输，而首要工作就是编码，文档的最小编码长度即为自信息量，平均编码长度为熵，而每个关键词对文档的编码都有不同的贡献，根据贡献的大小量化其重要性，即TF/IDF。